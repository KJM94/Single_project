{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KJM94/Single_project/blob/main/%EC%9B%B9%20%EA%B8%B0%EC%82%AC%20%EC%B6%94%EC%B2%9C%20AI%20%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3532fb5a",
      "metadata": {
        "id": "3532fb5a",
        "outputId": "89e3403d-41b3-4b6b-b371-6c3b195722e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_2806\n",
            "1  USER_0000           390\n",
            "2  USER_0000  ARTICLE_1053\n",
            "3  USER_0000          2156\n",
            "4  USER_0000  ARTICLE_2642\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load datasets\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Generate content-based recommendations\n",
        "content_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    viewed_articles = view_log[view_log['userID'] == user]['articleID'].tolist()\n",
        "    recommendations = []\n",
        "    for article in viewed_articles:\n",
        "        recommendations.extend(get_content_recommendations(article, num_recommendations=1))\n",
        "    recommendations = list(set(recommendations))[:5]\n",
        "    for rec in recommendations:\n",
        "        content_recommendations.append([user, rec])\n",
        "\n",
        "# Convert content-based recommendations to DataFrame\n",
        "content_recommendations_df = pd.DataFrame(content_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    cf_scores = user_similarity[user_idx].dot(user_article_matrix) / np.array([np.abs(user_similarity[user_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1][:num_recommendations]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=1))\n",
        "    cb_recommendations = list(set(cb_recommendations))[:num_recommendations]\n",
        "\n",
        "    # Combine recommendations\n",
        "    recommendations = list(set(cf_recommendations) | set(cb_recommendations))[:num_recommendations]\n",
        "    return recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78958e87",
      "metadata": {
        "id": "78958e87",
        "outputId": "4c1653ba-66c1-4362-a33a-08f67e12de27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000           390\n",
            "1  USER_0000  ARTICLE_1052\n",
            "2  USER_0000           635\n",
            "3  USER_0000          1498\n",
            "4  USER_0000          1176\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load datasets\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.5, weight_cb=0.5):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    cf_scores = user_similarity[user_idx].dot(user_article_matrix) / np.array([np.abs(user_similarity[user_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=1))\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf * cf_scores[article]\n",
        "    for article in cb_recommendations:\n",
        "        idx = article_indices.get(article, None)\n",
        "        if idx is not None:\n",
        "            combined_scores[article] = combined_scores.get(article, 0) + weight_cb * cosine_sim[article_indices[viewed_articles[0]]][idx]\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "398e1337",
      "metadata": {
        "id": "398e1337",
        "outputId": "b698012a-9462-4193-a87a-53555ccf645c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID articleID\n",
            "0  USER_0000       390\n",
            "1  USER_0000      2156\n",
            "2  USER_0000      2713\n",
            "3  USER_0000      2212\n",
            "4  USER_0000      1282\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load datasets\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    user_sim_scores = user_similarity[user_idx]\n",
        "\n",
        "    # Consider only top N similar users\n",
        "    top_users_idx = np.argsort(user_sim_scores)[::-1][:top_n_similar_users]\n",
        "    cf_scores = user_sim_scores[top_users_idx].dot(user_article_matrix.iloc[top_users_idx]) / np.array([np.abs(user_sim_scores[top_users_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))  # Increase number of recommendations\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf * cf_scores[article]\n",
        "    for article in cb_recommendations:\n",
        "        idx = article_indices.get(article, None)\n",
        "        if idx is not None:\n",
        "            combined_scores[article] = combined_scores.get(article, 0) + weight_cb * cosine_sim[article_indices[viewed_articles[0]]][idx]\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_tuned.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bd9d22b",
      "metadata": {
        "id": "3bd9d22b",
        "outputId": "74e9df64-e091-46bb-8ea9-d92e2d4a8b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID articleID\n",
            "0  USER_0000       390\n",
            "1  USER_0000      2156\n",
            "2  USER_0000      2713\n",
            "3  USER_0000      2212\n",
            "4  USER_0000      1282\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    user_sim_scores = user_similarity[user_idx]\n",
        "\n",
        "    # Consider only top N similar users\n",
        "    top_users_idx = np.argsort(user_sim_scores)[::-1][:top_n_similar_users]\n",
        "    cf_scores = user_sim_scores[top_users_idx].dot(user_article_matrix.iloc[top_users_idx]) / np.array([np.abs(user_sim_scores[top_users_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))  # Increase number of recommendations\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf * cf_scores[article]\n",
        "    for article in cb_recommendations:\n",
        "        idx = article_indices.get(article, None)\n",
        "        if idx is not None:\n",
        "            combined_scores[article] = combined_scores.get(article, 0) + weight_cb * cosine_sim[article_indices[viewed_articles[0]]][idx]\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5123a549",
      "metadata": {
        "id": "5123a549",
        "outputId": "01b3638a-91d1-4ced-897b-e6c52440afe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1568\n",
            "1  USER_0000  ARTICLE_2720\n",
            "2  USER_0000  ARTICLE_1948\n",
            "3  USER_0000  ARTICLE_2147\n",
            "4  USER_0000  ARTICLE_0561\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Normalize the matrix\n",
        "user_article_matrix_norm = user_article_matrix.subtract(user_article_matrix.mean(axis=1), axis=0)\n",
        "\n",
        "# Perform SVD\n",
        "U, sigma, Vt = svds(user_article_matrix_norm, k=50)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Calculate predicted ratings\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_article_matrix.mean(axis=1).values.reshape(-1, 1)\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=user_article_matrix.columns, index=user_article_matrix.index)\n",
        "\n",
        "# Hybrid recommendation function\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    cf_recommendations = predicted_ratings_df.loc[user_id].sort_values(ascending=False).index.tolist()\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf\n",
        "    for article in cb_recommendations:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cb\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47b6242d",
      "metadata": {
        "id": "47b6242d",
        "outputId": "0fc827d3-547b-458c-e7fc-161fd643373c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1568\n",
            "1  USER_0000  ARTICLE_2720\n",
            "2  USER_0000  ARTICLE_1948\n",
            "3  USER_0000  ARTICLE_2147\n",
            "4  USER_0000  ARTICLE_0561\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Normalize the matrix\n",
        "user_article_matrix_norm = user_article_matrix.subtract(user_article_matrix.mean(axis=1), axis=0)\n",
        "\n",
        "# Perform SVD\n",
        "U, sigma, Vt = svds(user_article_matrix_norm, k=50)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Calculate predicted ratings\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_article_matrix.mean(axis=1).values.reshape(-1, 1)\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=user_article_matrix.columns, index=user_article_matrix.index)\n",
        "\n",
        "# Hybrid recommendation function\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    cf_recommendations = predicted_ratings_df.loc[user_id].sort_values(ascending=False).index.tolist()\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf\n",
        "    for article in cb_recommendations:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cb\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}