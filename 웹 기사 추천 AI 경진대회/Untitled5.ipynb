{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KJM94/Single_project/blob/main/%EC%9B%B9%20%EA%B8%B0%EC%82%AC%20%EC%B6%94%EC%B2%9C%20AI%20%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3532fb5a",
      "metadata": {
        "id": "3532fb5a",
        "outputId": "c953af38-d375-4fd8-d030-dd5eab60b8ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_2806\n",
            "1  USER_0000           390\n",
            "2  USER_0000  ARTICLE_1053\n",
            "3  USER_0000          2156\n",
            "4  USER_0000  ARTICLE_2642\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load datasets\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Generate content-based recommendations\n",
        "content_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    viewed_articles = view_log[view_log['userID'] == user]['articleID'].tolist()\n",
        "    recommendations = []\n",
        "    for article in viewed_articles:\n",
        "        recommendations.extend(get_content_recommendations(article, num_recommendations=1))\n",
        "    recommendations = list(set(recommendations))[:5]\n",
        "    for rec in recommendations:\n",
        "        content_recommendations.append([user, rec])\n",
        "\n",
        "# Convert content-based recommendations to DataFrame\n",
        "content_recommendations_df = pd.DataFrame(content_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    cf_scores = user_similarity[user_idx].dot(user_article_matrix) / np.array([np.abs(user_similarity[user_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1][:num_recommendations]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=1))\n",
        "    cb_recommendations = list(set(cb_recommendations))[:num_recommendations]\n",
        "\n",
        "    # Combine recommendations\n",
        "    recommendations = list(set(cf_recommendations) | set(cb_recommendations))[:num_recommendations]\n",
        "    return recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78958e87",
      "metadata": {
        "id": "78958e87",
        "outputId": "65147fe6-df47-4b6c-e18d-876a855821a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000           390\n",
            "1  USER_0000  ARTICLE_1052\n",
            "2  USER_0000           635\n",
            "3  USER_0000          1498\n",
            "4  USER_0000          1176\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load datasets\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.5, weight_cb=0.5):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    cf_scores = user_similarity[user_idx].dot(user_article_matrix) / np.array([np.abs(user_similarity[user_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=1))\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf * cf_scores[article]\n",
        "    for article in cb_recommendations:\n",
        "        idx = article_indices.get(article, None)\n",
        "        if idx is not None:\n",
        "            combined_scores[article] = combined_scores.get(article, 0) + weight_cb * cosine_sim[article_indices[viewed_articles[0]]][idx]\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "398e1337",
      "metadata": {
        "id": "398e1337",
        "outputId": "853e61e2-0e13-4d04-d9f5-08fe874ffb96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID articleID\n",
            "0  USER_0000       390\n",
            "1  USER_0000      2156\n",
            "2  USER_0000      2713\n",
            "3  USER_0000      2212\n",
            "4  USER_0000      1282\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load datasets\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    user_sim_scores = user_similarity[user_idx]\n",
        "\n",
        "    # Consider only top N similar users\n",
        "    top_users_idx = np.argsort(user_sim_scores)[::-1][:top_n_similar_users]\n",
        "    cf_scores = user_sim_scores[top_users_idx].dot(user_article_matrix.iloc[top_users_idx]) / np.array([np.abs(user_sim_scores[top_users_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))  # Increase number of recommendations\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf * cf_scores[article]\n",
        "    for article in cb_recommendations:\n",
        "        idx = article_indices.get(article, None)\n",
        "        if idx is not None:\n",
        "            combined_scores[article] = combined_scores.get(article, 0) + weight_cb * cosine_sim[article_indices[viewed_articles[0]]][idx]\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_tuned.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bd9d22b",
      "metadata": {
        "id": "3bd9d22b",
        "outputId": "408e5143-72c5-4977-d5bd-5ea476ffa998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID articleID\n",
            "0  USER_0000       390\n",
            "1  USER_0000      2156\n",
            "2  USER_0000      2713\n",
            "3  USER_0000      2212\n",
            "4  USER_0000      1282\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    user_sim_scores = user_similarity[user_idx]\n",
        "\n",
        "    # Consider only top N similar users\n",
        "    top_users_idx = np.argsort(user_sim_scores)[::-1][:top_n_similar_users]\n",
        "    cf_scores = user_sim_scores[top_users_idx].dot(user_article_matrix.iloc[top_users_idx]) / np.array([np.abs(user_sim_scores[top_users_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))  # Increase number of recommendations\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf * cf_scores[article]\n",
        "    for article in cb_recommendations:\n",
        "        idx = article_indices.get(article, None)\n",
        "        if idx is not None:\n",
        "            combined_scores[article] = combined_scores.get(article, 0) + weight_cb * cosine_sim[article_indices[viewed_articles[0]]][idx]\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5123a549",
      "metadata": {
        "id": "5123a549",
        "outputId": "3a0237e2-33e6-4439-efd0-7b548c204c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1568\n",
            "1  USER_0000  ARTICLE_2720\n",
            "2  USER_0000  ARTICLE_1948\n",
            "3  USER_0000  ARTICLE_2147\n",
            "4  USER_0000  ARTICLE_0561\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Normalize the matrix\n",
        "user_article_matrix_norm = user_article_matrix.subtract(user_article_matrix.mean(axis=1), axis=0)\n",
        "\n",
        "# Perform SVD\n",
        "U, sigma, Vt = svds(user_article_matrix_norm, k=50)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Calculate predicted ratings\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_article_matrix.mean(axis=1).values.reshape(-1, 1)\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=user_article_matrix.columns, index=user_article_matrix.index)\n",
        "\n",
        "# Hybrid recommendation function\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    cf_recommendations = predicted_ratings_df.loc[user_id].sort_values(ascending=False).index.tolist()\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf\n",
        "    for article in cb_recommendations:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cb\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47b6242d",
      "metadata": {
        "id": "47b6242d",
        "outputId": "d04d0130-0542-4fbd-81e2-a175ba00c920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1568\n",
            "1  USER_0000  ARTICLE_2720\n",
            "2  USER_0000  ARTICLE_1948\n",
            "3  USER_0000  ARTICLE_2147\n",
            "4  USER_0000  ARTICLE_0561\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Normalize the matrix\n",
        "user_article_matrix_norm = user_article_matrix.subtract(user_article_matrix.mean(axis=1), axis=0)\n",
        "\n",
        "# Perform SVD\n",
        "U, sigma, Vt = svds(user_article_matrix_norm, k=50)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Calculate predicted ratings\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_article_matrix.mean(axis=1).values.reshape(-1, 1)\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=user_article_matrix.columns, index=user_article_matrix.index)\n",
        "\n",
        "# Hybrid recommendation function\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    cf_recommendations = predicted_ratings_df.loc[user_id].sort_values(ascending=False).index.tolist()\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf\n",
        "    for article in cb_recommendations:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cb\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2701ca73",
      "metadata": {
        "id": "2701ca73",
        "outputId": "82393d76-622f-4dc2-afbc-08758baa37f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1568\n",
            "1  USER_0000  ARTICLE_2720\n",
            "2  USER_0000  ARTICLE_1948\n",
            "3  USER_0000  ARTICLE_2147\n",
            "4  USER_0000  ARTICLE_0561\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Normalize the matrix\n",
        "user_article_matrix_norm = user_article_matrix.subtract(user_article_matrix.mean(axis=1), axis=0)\n",
        "\n",
        "# Perform SVD\n",
        "U, sigma, Vt = svds(user_article_matrix_norm, k=50)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Calculate predicted ratings\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_article_matrix.mean(axis=1).values.reshape(-1, 1)\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=user_article_matrix.columns, index=user_article_matrix.index)\n",
        "\n",
        "# Function to get hybrid recommendations\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3):\n",
        "    # Collaborative filtering recommendations\n",
        "    cf_recommendations = predicted_ratings_df.loc[user_id].sort_values(ascending=False).index.tolist()\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf\n",
        "    for article in cb_recommendations:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cb\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "024a0254",
      "metadata": {
        "id": "024a0254",
        "outputId": "ee0219cc-c3e3-4607-f5c0-b86e3d6b3602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1305\n",
            "1  USER_0000  ARTICLE_0084\n",
            "2  USER_0000  ARTICLE_2081\n",
            "3  USER_0000  ARTICLE_2449\n",
            "4  USER_0000  ARTICLE_1568\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['Content'])\n",
        "\n",
        "# 기사 ID를 인덱스와 매핑\n",
        "indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 콘텐츠 기반 추천\n",
        "def get_content_based_recommendations(article_id, num_recommendations=5):\n",
        "    idx = indices[article_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices]\n",
        "\n",
        "# 사용자-기사 상호작용 매트릭스 생성\n",
        "interaction_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# 상호작용 매트릭스를 실수형으로 변환\n",
        "interaction_matrix = interaction_matrix.astype(np.float64)\n",
        "\n",
        "# SVD 수행\n",
        "U, sigma, Vt = svds(interaction_matrix, k=50)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# 예측 평점 계산\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "predicted_ratings = pd.DataFrame(predicted_ratings, columns=interaction_matrix.columns)\n",
        "\n",
        "# 협업 필터링 기반 추천\n",
        "def collaborative_filtering(user_id, num_recommendations=5):\n",
        "    user_idx = interaction_matrix.index.get_loc(user_id)\n",
        "    sorted_user_predictions = predicted_ratings.iloc[user_idx].sort_values(ascending=False)\n",
        "    return sorted_user_predictions.index[:num_recommendations]\n",
        "\n",
        "# 하이브리드 추천 시스템\n",
        "def hybrid_recommendation_system(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3):\n",
        "    cf_recommendations = collaborative_filtering(user_id, num_recommendations * 2)\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    cb_recommendations = []\n",
        "    for article_id in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_based_recommendations(article_id, num_recommendations=2))\n",
        "    combined_recommendations = list(set(cf_recommendations).union(set(cb_recommendations)))\n",
        "    combined_scores = {article: weight_cf for article in cf_recommendations}\n",
        "    for article in cb_recommendations:\n",
        "        if article in combined_scores:\n",
        "            combined_scores[article] += weight_cb\n",
        "        else:\n",
        "            combined_scores[article] = weight_cb\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "# 추천 결과 생성\n",
        "results = []\n",
        "for user_id in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation_system(user_id)\n",
        "    for article_id in recommendations:\n",
        "        results.append([user_id, article_id])\n",
        "\n",
        "# 결과 저장\n",
        "results_df = pd.DataFrame(results, columns=['userID', 'articleID'])\n",
        "results_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(results_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c400d5",
      "metadata": {
        "id": "d5c400d5",
        "outputId": "f5cc5063-090d-4550-8e17-171962f148ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1305\n",
            "1  USER_0000  ARTICLE_0084\n",
            "2  USER_0000  ARTICLE_2081\n",
            "3  USER_0000  ARTICLE_0830\n",
            "4  USER_0000  ARTICLE_2147\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from scipy.sparse.linalg import svds\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_df=0.8, min_df=2, ngram_range=(1, 2))\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['Content'])\n",
        "\n",
        "# 기사 ID를 인덱스와 매핑\n",
        "indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 콘텐츠 기반 추천\n",
        "def get_content_based_recommendations(article_id, num_recommendations=5):\n",
        "    idx = indices[article_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices]\n",
        "\n",
        "# 사용자-기사 상호작용 매트릭스 생성\n",
        "interaction_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# 상호작용 매트릭스를 실수형으로 변환\n",
        "interaction_matrix = interaction_matrix.astype(np.float64)\n",
        "\n",
        "# SVD 수행 (차원 수 조정)\n",
        "U, sigma, Vt = svds(interaction_matrix, k=100)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# 예측 평점 계산\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "predicted_ratings = pd.DataFrame(predicted_ratings, columns=interaction_matrix.columns)\n",
        "\n",
        "# 협업 필터링 기반 추천\n",
        "def collaborative_filtering(user_id, num_recommendations=5):\n",
        "    user_idx = interaction_matrix.index.get_loc(user_id)\n",
        "    sorted_user_predictions = predicted_ratings.iloc[user_idx].sort_values(ascending=False)\n",
        "    return sorted_user_predictions.index[:num_recommendations]\n",
        "\n",
        "# 하이브리드 추천 시스템\n",
        "def hybrid_recommendation_system(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3):\n",
        "    cf_recommendations = collaborative_filtering(user_id, num_recommendations * 2)\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    cb_recommendations = []\n",
        "    for article_id in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_based_recommendations(article_id, num_recommendations=2))\n",
        "    combined_recommendations = list(set(cf_recommendations).union(set(cb_recommendations)))\n",
        "    combined_scores = {article: weight_cf for article in cf_recommendations}\n",
        "    for article in cb_recommendations:\n",
        "        if article in combined_scores:\n",
        "            combined_scores[article] += weight_cb\n",
        "        else:\n",
        "            combined_scores[article] = weight_cb\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "# 추천 결과 생성\n",
        "results = []\n",
        "for user_id in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation_system(user_id)\n",
        "    for article_id in recommendations:\n",
        "        results.append([user_id, article_id])\n",
        "\n",
        "# 결과 저장\n",
        "results_df = pd.DataFrame(results, columns=['userID', 'articleID'])\n",
        "results_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(results_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e44ee4cd",
      "metadata": {
        "id": "e44ee4cd",
        "outputId": "e861494c-c543-4f2d-f57b-621b1d685631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3008 entries, 0 to 3007\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   articleID    3008 non-null   object\n",
            " 1   Title        3008 non-null   object\n",
            " 2   Content      3008 non-null   object\n",
            " 3   Format       3008 non-null   object\n",
            " 4   Language     3008 non-null   object\n",
            " 5   userID       3008 non-null   object\n",
            " 6   userCountry  659 non-null    object\n",
            " 7   userRegion   657 non-null    object\n",
            "dtypes: object(8)\n",
            "memory usage: 188.1+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42717 entries, 0 to 42716\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   userID       42717 non-null  object\n",
            " 1   articleID    42717 non-null  object\n",
            " 2   userRegion   42717 non-null  object\n",
            " 3   userCountry  42717 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 1.3+ MB\n",
            "None\n",
            "count      3008.000000\n",
            "mean       5428.732380\n",
            "std        6219.370202\n",
            "min         301.000000\n",
            "25%        1910.500000\n",
            "50%        3713.000000\n",
            "75%        6738.250000\n",
            "max      122568.000000\n",
            "Name: content_length, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# 데이터 분석\n",
        "print(article_info.info())\n",
        "print(view_log.info())\n",
        "\n",
        "# 기사 내용 길이 확인\n",
        "article_info['content_length'] = article_info['Content'].apply(len)\n",
        "print(article_info['content_length'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c51fdea",
      "metadata": {
        "id": "1c51fdea",
        "outputId": "a7662f69-5a61-4b1c-c1fb-a81767a29c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1305\n",
            "1  USER_0000  ARTICLE_2147\n",
            "2  USER_0000  ARTICLE_1948\n",
            "3  USER_0000  ARTICLE_1281\n",
            "4  USER_0000  ARTICLE_2720\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from scipy.sparse.linalg import svds\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_df=0.7, min_df=3, ngram_range=(1, 3))\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['Content'])\n",
        "\n",
        "# 기사 ID를 인덱스와 매핑\n",
        "indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 콘텐츠 기반 추천\n",
        "def get_content_based_recommendations(article_id, num_recommendations=5):\n",
        "    idx = indices[article_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices]\n",
        "\n",
        "# 사용자-기사 상호작용 매트릭스 생성\n",
        "interaction_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# 상호작용 매트릭스를 실수형으로 변환\n",
        "interaction_matrix = interaction_matrix.astype(np.float64)\n",
        "\n",
        "# SVD 수행 (차원 수 조정)\n",
        "U, sigma, Vt = svds(interaction_matrix, k=75)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# 예측 평점 계산\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "predicted_ratings = pd.DataFrame(predicted_ratings, columns=interaction_matrix.columns)\n",
        "\n",
        "# 협업 필터링 기반 추천\n",
        "def collaborative_filtering(user_id, num_recommendations=5):\n",
        "    user_idx = interaction_matrix.index.get_loc(user_id)\n",
        "    sorted_user_predictions = predicted_ratings.iloc[user_idx].sort_values(ascending=False)\n",
        "    return sorted_user_predictions.index[:num_recommendations]\n",
        "\n",
        "# 하이브리드 추천 시스템\n",
        "def hybrid_recommendation_system(user_id, num_recommendations=5, weight_cf=0.8, weight_cb=0.2):\n",
        "    cf_recommendations = collaborative_filtering(user_id, num_recommendations * 2)\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    cb_recommendations = []\n",
        "    for article_id in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_based_recommendations(article_id, num_recommendations=2))\n",
        "    combined_recommendations = list(set(cf_recommendations).union(set(cb_recommendations)))\n",
        "    combined_scores = {article: weight_cf for article in cf_recommendations}\n",
        "    for article in cb_recommendations:\n",
        "        if article in combined_scores:\n",
        "            combined_scores[article] += weight_cb\n",
        "        else:\n",
        "            combined_scores[article] = weight_cb\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "# 추천 결과 생성\n",
        "results = []\n",
        "for user_id in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation_system(user_id)\n",
        "    for article_id in recommendations:\n",
        "        results.append([user_id, article_id])\n",
        "\n",
        "# 결과 저장\n",
        "results_df = pd.DataFrame(results, columns=['userID', 'articleID'])\n",
        "results_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(results_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "593a9f9e",
      "metadata": {
        "id": "593a9f9e",
        "outputId": "d4c44d92-0540-44e9-a0c4-4ce5d0eaa6fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1305\n",
            "1  USER_0000  ARTICLE_0084\n",
            "2  USER_0000  ARTICLE_2081\n",
            "3  USER_0000  ARTICLE_0830\n",
            "4  USER_0000  ARTICLE_2147\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from scipy.sparse.linalg import svds\n",
        "import re\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# 텍스트 전처리\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # 소문자로 변환\n",
        "    text = re.sub(r'\\d+', '', text)  # 숫자 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 공백 제거\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # 구두점 제거\n",
        "    return text\n",
        "\n",
        "article_info['Content'] = article_info['Content'].apply(preprocess_text)\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_df=0.6, min_df=5, ngram_range=(1, 3))\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['Content'])\n",
        "\n",
        "# 기사 ID를 인덱스와 매핑\n",
        "indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 콘텐츠 기반 추천\n",
        "def get_content_based_recommendations(article_id, num_recommendations=5):\n",
        "    idx = indices[article_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices]\n",
        "\n",
        "# 사용자-기사 상호작용 매트릭스 생성\n",
        "interaction_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# 상호작용 매트릭스를 실수형으로 변환\n",
        "interaction_matrix = interaction_matrix.astype(np.float64)\n",
        "\n",
        "# SVD 수행 (차원 수 조정)\n",
        "U, sigma, Vt = svds(interaction_matrix, k=100)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# 예측 평점 계산\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "predicted_ratings = pd.DataFrame(predicted_ratings, columns=interaction_matrix.columns)\n",
        "\n",
        "# 협업 필터링 기반 추천\n",
        "def collaborative_filtering(user_id, num_recommendations=5):\n",
        "    user_idx = interaction_matrix.index.get_loc(user_id)\n",
        "    sorted_user_predictions = predicted_ratings.iloc[user_idx].sort_values(ascending=False)\n",
        "    return sorted_user_predictions.index[:num_recommendations]\n",
        "\n",
        "# 하이브리드 추천 시스템\n",
        "def hybrid_recommendation_system(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3):\n",
        "    cf_recommendations = collaborative_filtering(user_id, num_recommendations * 2)\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    cb_recommendations = []\n",
        "    for article_id in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_based_recommendations(article_id, num_recommendations=2))\n",
        "    combined_recommendations = list(set(cf_recommendations).union(set(cb_recommendations)))\n",
        "    combined_scores = {article: weight_cf for article in cf_recommendations}\n",
        "    for article in cb_recommendations:\n",
        "        if article in combined_scores:\n",
        "            combined_scores[article] += weight_cb\n",
        "        else:\n",
        "            combined_scores[article] = weight_cb\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "# 추천 결과 생성\n",
        "results = []\n",
        "for user_id in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation_system(user_id)\n",
        "    for article_id in recommendations:\n",
        "        results.append([user_id, article_id])\n",
        "\n",
        "# 결과 저장\n",
        "results_df = pd.DataFrame(results, columns=['userID', 'articleID'])\n",
        "results_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(results_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6ea5e1f",
      "metadata": {
        "id": "a6ea5e1f",
        "outputId": "da74c51f-b077-45c9-8e6f-5ecae250655e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1305\n",
            "1  USER_0000  ARTICLE_0084\n",
            "2  USER_0000  ARTICLE_2081\n",
            "3  USER_0000  ARTICLE_0830\n",
            "4  USER_0000  ARTICLE_0287\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from scipy.sparse.linalg import svds\n",
        "import re\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# 텍스트 전처리\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # 소문자로 변환\n",
        "    text = re.sub(r'\\d+', '', text)  # 숫자 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 공백 제거\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # 구두점 제거\n",
        "    return text\n",
        "\n",
        "article_info['Content'] = article_info['Content'].apply(preprocess_text)\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_df=0.5, min_df=3, ngram_range=(1, 2))\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['Content'])\n",
        "\n",
        "# 기사 ID를 인덱스와 매핑\n",
        "indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 콘텐츠 기반 추천\n",
        "def get_content_based_recommendations(article_id, num_recommendations=5):\n",
        "    idx = indices[article_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices]\n",
        "\n",
        "# 사용자-기사 상호작용 매트릭스 생성\n",
        "interaction_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# 상호작용 매트릭스를 실수형으로 변환\n",
        "interaction_matrix = interaction_matrix.astype(np.float64)\n",
        "\n",
        "# SVD 수행 (차원 수 조정)\n",
        "U, sigma, Vt = svds(interaction_matrix, k=50)  # 차원 수 50으로 줄임\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# 예측 평점 계산\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "predicted_ratings = pd.DataFrame(predicted_ratings, columns=interaction_matrix.columns)\n",
        "\n",
        "# 협업 필터링 기반 추천\n",
        "def collaborative_filtering(user_id, num_recommendations=5):\n",
        "    user_idx = interaction_matrix.index.get_loc(user_id)\n",
        "    sorted_user_predictions = predicted_ratings.iloc[user_idx].sort_values(ascending=False)\n",
        "    return sorted_user_predictions.index[:num_recommendations]\n",
        "\n",
        "# 하이브리드 추천 시스템\n",
        "def hybrid_recommendation_system(user_id, num_recommendations=5, weight_cf=0.5, weight_cb=0.5):\n",
        "    cf_recommendations = collaborative_filtering(user_id, num_recommendations * 2)\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    cb_recommendations = []\n",
        "    for article_id in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_based_recommendations(article_id, num_recommendations=2))\n",
        "    combined_recommendations = list(set(cf_recommendations).union(set(cb_recommendations)))\n",
        "    combined_scores = {article: weight_cf for article in cf_recommendations}\n",
        "    for article in cb_recommendations:\n",
        "        if article in combined_scores:\n",
        "            combined_scores[article] += weight_cb\n",
        "        else:\n",
        "            combined_scores[article] = weight_cb\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "# 추천 결과 생성\n",
        "results = []\n",
        "for user_id in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation_system(user_id)\n",
        "    for article_id in recommendations:\n",
        "        results.append([user_id, article_id])\n",
        "\n",
        "# 결과 저장\n",
        "results_df = pd.DataFrame(results, columns=['userID', 'articleID'])\n",
        "results_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(results_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2d6f2be",
      "metadata": {
        "id": "e2d6f2be",
        "outputId": "a4f8c677-3cff-4609-f630-ba61167b2207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1305\n",
            "1  USER_0000  ARTICLE_0084\n",
            "2  USER_0000  ARTICLE_2081\n",
            "3  USER_0000  ARTICLE_0830\n",
            "4  USER_0000  ARTICLE_0428\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from scipy.sparse.linalg import svds\n",
        "import re\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# 텍스트 전처리\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # 소문자로 변환\n",
        "    text = re.sub(r'\\d+', '', text)  # 숫자 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 공백 제거\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # 구두점 제거\n",
        "    return text\n",
        "\n",
        "article_info['Content'] = article_info['Content'].apply(preprocess_text)\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_df=0.6, min_df=3, ngram_range=(1, 2))\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['Content'])\n",
        "\n",
        "# 기사 ID를 인덱스와 매핑\n",
        "indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 콘텐츠 기반 추천\n",
        "def get_content_based_recommendations(article_id, num_recommendations=5):\n",
        "    idx = indices[article_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices]\n",
        "\n",
        "# 상위 사용자 및 아이템 필터링\n",
        "top_users = view_log['userID'].value_counts().index[:1000]\n",
        "top_articles = view_log['articleID'].value_counts().index[:1000]\n",
        "\n",
        "filtered_view_log = view_log[view_log['userID'].isin(top_users) & view_log['articleID'].isin(top_articles)]\n",
        "\n",
        "# 사용자-기사 상호작용 매트릭스 생성\n",
        "interaction_matrix = filtered_view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# 상호작용 매트릭스를 실수형으로 변환\n",
        "interaction_matrix = interaction_matrix.astype(np.float64)\n",
        "\n",
        "# SVD 수행 (차원 수 조정)\n",
        "U, sigma, Vt = svds(interaction_matrix, k=50)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# 예측 평점 계산\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "predicted_ratings = pd.DataFrame(predicted_ratings, columns=interaction_matrix.columns)\n",
        "\n",
        "# 협업 필터링 기반 추천\n",
        "def collaborative_filtering(user_id, num_recommendations=5):\n",
        "    user_idx = interaction_matrix.index.get_loc(user_id)\n",
        "    sorted_user_predictions = predicted_ratings.iloc[user_idx].sort_values(ascending=False)\n",
        "    return sorted_user_predictions.index[:num_recommendations]\n",
        "\n",
        "# 하이브리드 추천 시스템\n",
        "def hybrid_recommendation_system(user_id, num_recommendations=5, weight_cf=0.5, weight_cb=0.5):\n",
        "    cf_recommendations = collaborative_filtering(user_id, num_recommendations * 2)\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    cb_recommendations = []\n",
        "    for article_id in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_based_recommendations(article_id, num_recommendations=2))\n",
        "    combined_recommendations = list(set(cf_recommendations).union(set(cb_recommendations)))\n",
        "    combined_scores = {article: weight_cf for article in cf_recommendations}\n",
        "    for article in cb_recommendations:\n",
        "        if article in combined_scores:\n",
        "            combined_scores[article] += weight_cb\n",
        "        else:\n",
        "            combined_scores[article] = weight_cb\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "# 추천 결과 생성\n",
        "results = []\n",
        "for user_id in filtered_view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation_system(user_id)\n",
        "    for article_id in recommendations:\n",
        "        results.append([user_id, article_id])\n",
        "\n",
        "# 결과 저장\n",
        "results_df = pd.DataFrame(results, columns=['userID', 'articleID'])\n",
        "results_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(results_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd66160",
      "metadata": {
        "id": "efd66160",
        "outputId": "8f7e1bda-143d-4600-bdd8-0480f2124dc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1305\n",
            "1  USER_0000  ARTICLE_0084\n",
            "2  USER_0000  ARTICLE_2081\n",
            "3  USER_0000  ARTICLE_2449\n",
            "4  USER_0000  ARTICLE_0428\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from scipy.sparse.linalg import svds\n",
        "import re\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# 텍스트 전처리\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # 소문자로 변환\n",
        "    text = re.sub(r'\\d+', '', text)  # 숫자 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 공백 제거\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # 구두점 제거\n",
        "    return text\n",
        "\n",
        "article_info['Content'] = article_info['Content'].apply(preprocess_text)\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_df=0.7, min_df=2, ngram_range=(1, 1))\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['Content'])\n",
        "\n",
        "# 기사 ID를 인덱스와 매핑\n",
        "indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 콘텐츠 기반 추천\n",
        "def get_content_based_recommendations(article_id, num_recommendations=5):\n",
        "    idx = indices[article_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices]\n",
        "\n",
        "# 사용자-기사 상호작용 매트릭스 생성\n",
        "interaction_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# 상호작용 매트릭스를 실수형으로 변환\n",
        "interaction_matrix = interaction_matrix.astype(np.float64)\n",
        "\n",
        "# SVD 수행 (차원 수 조정)\n",
        "U, sigma, Vt = svds(interaction_matrix, k=30)  # 차원 수 30으로 조정\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# 예측 평점 계산\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "predicted_ratings = pd.DataFrame(predicted_ratings, columns=interaction_matrix.columns)\n",
        "\n",
        "# 협업 필터링 기반 추천\n",
        "def collaborative_filtering(user_id, num_recommendations=5):\n",
        "    user_idx = interaction_matrix.index.get_loc(user_id)\n",
        "    sorted_user_predictions = predicted_ratings.iloc[user_idx].sort_values(ascending=False)\n",
        "    return sorted_user_predictions.index[:num_recommendations]\n",
        "\n",
        "# 하이브리드 추천 시스템\n",
        "def hybrid_recommendation_system(user_id, num_recommendations=5, weight_cf=0.6, weight_cb=0.4):\n",
        "    cf_recommendations = collaborative_filtering(user_id, num_recommendations * 2)\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    cb_recommendations = []\n",
        "    for article_id in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_based_recommendations(article_id, num_recommendations=2))\n",
        "    combined_recommendations = list(set(cf_recommendations).union(set(cb_recommendations)))\n",
        "    combined_scores = {article: weight_cf for article in cf_recommendations}\n",
        "    for article in cb_recommendations:\n",
        "        if article in combined_scores:\n",
        "            combined_scores[article] += weight_cb\n",
        "        else:\n",
        "            combined_scores[article] = weight_cb\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "# 추천 결과 생성\n",
        "results = []\n",
        "for user_id in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation_system(user_id)\n",
        "    for article_id in recommendations:\n",
        "        results.append([user_id, article_id])\n",
        "\n",
        "# 결과 저장\n",
        "results_df = pd.DataFrame(results, columns=['userID', 'articleID'])\n",
        "results_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(results_df.head())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}