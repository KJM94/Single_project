{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KJM94/Single_project/blob/main/%EC%9B%B9%20%EA%B8%B0%EC%82%AC%20%EC%B6%94%EC%B2%9C%20AI%20%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3532fb5a",
      "metadata": {
        "id": "3532fb5a",
        "outputId": "c922ba69-2e59-4a19-bb29-0327ce2c4d82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_2806\n",
            "1  USER_0000           390\n",
            "2  USER_0000  ARTICLE_1053\n",
            "3  USER_0000          2156\n",
            "4  USER_0000  ARTICLE_2642\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load datasets\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Generate content-based recommendations\n",
        "content_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    viewed_articles = view_log[view_log['userID'] == user]['articleID'].tolist()\n",
        "    recommendations = []\n",
        "    for article in viewed_articles:\n",
        "        recommendations.extend(get_content_recommendations(article, num_recommendations=1))\n",
        "    recommendations = list(set(recommendations))[:5]\n",
        "    for rec in recommendations:\n",
        "        content_recommendations.append([user, rec])\n",
        "\n",
        "# Convert content-based recommendations to DataFrame\n",
        "content_recommendations_df = pd.DataFrame(content_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    cf_scores = user_similarity[user_idx].dot(user_article_matrix) / np.array([np.abs(user_similarity[user_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1][:num_recommendations]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=1))\n",
        "    cb_recommendations = list(set(cb_recommendations))[:num_recommendations]\n",
        "\n",
        "    # Combine recommendations\n",
        "    recommendations = list(set(cf_recommendations) | set(cb_recommendations))[:num_recommendations]\n",
        "    return recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78958e87",
      "metadata": {
        "id": "78958e87",
        "outputId": "bc4db790-1fb0-48f9-8f22-94cb1ed2e838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000           390\n",
            "1  USER_0000  ARTICLE_1052\n",
            "2  USER_0000           635\n",
            "3  USER_0000          1498\n",
            "4  USER_0000          1176\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load datasets\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.5, weight_cb=0.5):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    cf_scores = user_similarity[user_idx].dot(user_article_matrix) / np.array([np.abs(user_similarity[user_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=1))\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf * cf_scores[article]\n",
        "    for article in cb_recommendations:\n",
        "        idx = article_indices.get(article, None)\n",
        "        if idx is not None:\n",
        "            combined_scores[article] = combined_scores.get(article, 0) + weight_cb * cosine_sim[article_indices[viewed_articles[0]]][idx]\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "398e1337",
      "metadata": {
        "id": "398e1337",
        "outputId": "8d2a66a3-b199-4187-c520-80f4d1862126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID articleID\n",
            "0  USER_0000       390\n",
            "1  USER_0000      2156\n",
            "2  USER_0000      2713\n",
            "3  USER_0000      2212\n",
            "4  USER_0000      1282\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load datasets\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    user_sim_scores = user_similarity[user_idx]\n",
        "\n",
        "    # Consider only top N similar users\n",
        "    top_users_idx = np.argsort(user_sim_scores)[::-1][:top_n_similar_users]\n",
        "    cf_scores = user_sim_scores[top_users_idx].dot(user_article_matrix.iloc[top_users_idx]) / np.array([np.abs(user_sim_scores[top_users_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))  # Increase number of recommendations\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf * cf_scores[article]\n",
        "    for article in cb_recommendations:\n",
        "        idx = article_indices.get(article, None)\n",
        "        if idx is not None:\n",
        "            combined_scores[article] = combined_scores.get(article, 0) + weight_cb * cosine_sim[article_indices[viewed_articles[0]]][idx]\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_tuned.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bd9d22b",
      "metadata": {
        "id": "3bd9d22b",
        "outputId": "f65c91d7-dfc3-47b3-a4d2-7e7900930fbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID articleID\n",
            "0  USER_0000       390\n",
            "1  USER_0000      2156\n",
            "2  USER_0000      2713\n",
            "3  USER_0000      2212\n",
            "4  USER_0000      1282\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Compute user similarity matrix using collaborative filtering\n",
        "user_similarity = cosine_similarity(user_article_matrix)\n",
        "\n",
        "# Hybrid approach: combining collaborative filtering with content-based filtering\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    user_idx = user_article_matrix.index.get_loc(user_id)\n",
        "    user_sim_scores = user_similarity[user_idx]\n",
        "\n",
        "    # Consider only top N similar users\n",
        "    top_users_idx = np.argsort(user_sim_scores)[::-1][:top_n_similar_users]\n",
        "    cf_scores = user_sim_scores[top_users_idx].dot(user_article_matrix.iloc[top_users_idx]) / np.array([np.abs(user_sim_scores[top_users_idx]).sum()])\n",
        "    cf_recommendations = np.argsort(cf_scores)[::-1]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))  # Increase number of recommendations\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf * cf_scores[article]\n",
        "    for article in cb_recommendations:\n",
        "        idx = article_indices.get(article, None)\n",
        "        if idx is not None:\n",
        "            combined_scores[article] = combined_scores.get(article, 0) + weight_cb * cosine_sim[article_indices[viewed_articles[0]]][idx]\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5123a549",
      "metadata": {
        "id": "5123a549",
        "outputId": "f9c8bcd8-8033-41ca-d872-d278bc8fbe13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1568\n",
            "1  USER_0000  ARTICLE_2720\n",
            "2  USER_0000  ARTICLE_1948\n",
            "3  USER_0000  ARTICLE_2147\n",
            "4  USER_0000  ARTICLE_0561\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Normalize the matrix\n",
        "user_article_matrix_norm = user_article_matrix.subtract(user_article_matrix.mean(axis=1), axis=0)\n",
        "\n",
        "# Perform SVD\n",
        "U, sigma, Vt = svds(user_article_matrix_norm, k=50)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Calculate predicted ratings\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_article_matrix.mean(axis=1).values.reshape(-1, 1)\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=user_article_matrix.columns, index=user_article_matrix.index)\n",
        "\n",
        "# Hybrid recommendation function\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    cf_recommendations = predicted_ratings_df.loc[user_id].sort_values(ascending=False).index.tolist()\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf\n",
        "    for article in cb_recommendations:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cb\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47b6242d",
      "metadata": {
        "id": "47b6242d",
        "outputId": "4564ac7f-df02-4ae3-bf52-9acf79cf575b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1568\n",
            "1  USER_0000  ARTICLE_2720\n",
            "2  USER_0000  ARTICLE_1948\n",
            "3  USER_0000  ARTICLE_2147\n",
            "4  USER_0000  ARTICLE_0561\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Normalize the matrix\n",
        "user_article_matrix_norm = user_article_matrix.subtract(user_article_matrix.mean(axis=1), axis=0)\n",
        "\n",
        "# Perform SVD\n",
        "U, sigma, Vt = svds(user_article_matrix_norm, k=50)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Calculate predicted ratings\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_article_matrix.mean(axis=1).values.reshape(-1, 1)\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=user_article_matrix.columns, index=user_article_matrix.index)\n",
        "\n",
        "# Hybrid recommendation function\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3, top_n_similar_users=10):\n",
        "    # Collaborative filtering recommendations\n",
        "    cf_recommendations = predicted_ratings_df.loc[user_id].sort_values(ascending=False).index.tolist()\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf\n",
        "    for article in cb_recommendations:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cb\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2701ca73",
      "metadata": {
        "id": "2701ca73",
        "outputId": "383910ee-fe18-4792-bb6f-21e9e4a81594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1568\n",
            "1  USER_0000  ARTICLE_2720\n",
            "2  USER_0000  ARTICLE_1948\n",
            "3  USER_0000  ARTICLE_2147\n",
            "4  USER_0000  ARTICLE_0561\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# Combine title and content for TF-IDF vectorization\n",
        "article_info['text'] = article_info['Title'] + \" \" + article_info['Content']\n",
        "\n",
        "# Compute the TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['text'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of articleID to index\n",
        "article_indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# Function to get article recommendations based on content similarity\n",
        "def get_content_recommendations(article_id, num_recommendations=5):\n",
        "    idx = article_indices.get(article_id, None)\n",
        "    if idx is None:\n",
        "        return []\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    article_indices_recommended = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices_recommended].values.tolist()\n",
        "\n",
        "# Generate user-article interaction matrix\n",
        "user_article_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Normalize the matrix\n",
        "user_article_matrix_norm = user_article_matrix.subtract(user_article_matrix.mean(axis=1), axis=0)\n",
        "\n",
        "# Perform SVD\n",
        "U, sigma, Vt = svds(user_article_matrix_norm, k=50)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Calculate predicted ratings\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_article_matrix.mean(axis=1).values.reshape(-1, 1)\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=user_article_matrix.columns, index=user_article_matrix.index)\n",
        "\n",
        "# Function to get hybrid recommendations\n",
        "def hybrid_recommendation(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3):\n",
        "    # Collaborative filtering recommendations\n",
        "    cf_recommendations = predicted_ratings_df.loc[user_id].sort_values(ascending=False).index.tolist()\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cb_recommendations = []\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    for article in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_recommendations(article, num_recommendations=2))\n",
        "    cb_recommendations = list(set(cb_recommendations))\n",
        "\n",
        "    # Combine and rank recommendations\n",
        "    combined_scores = {}\n",
        "    for article in cf_recommendations[:num_recommendations * 2]:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cf\n",
        "    for article in cb_recommendations:\n",
        "        combined_scores[article] = combined_scores.get(article, 0) + weight_cb\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    final_recommendations = [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# Generate hybrid recommendations for all users\n",
        "hybrid_recommendations = []\n",
        "for user in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation(user, num_recommendations=5)\n",
        "    for rec in recommendations:\n",
        "        hybrid_recommendations.append([user, rec])\n",
        "\n",
        "# Convert hybrid recommendations to DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations, columns=['userID', 'articleID'])\n",
        "\n",
        "# Save the hybrid recommendations to a CSV file\n",
        "hybrid_recommendations_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the recommendations\n",
        "print(hybrid_recommendations_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "024a0254",
      "metadata": {
        "id": "024a0254",
        "outputId": "13809ce8-d40a-48df-eb09-d0e2c909ac4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1305\n",
            "1  USER_0000  ARTICLE_0084\n",
            "2  USER_0000  ARTICLE_2081\n",
            "3  USER_0000  ARTICLE_2449\n",
            "4  USER_0000  ARTICLE_1568\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['Content'])\n",
        "\n",
        "# 기사 ID를 인덱스와 매핑\n",
        "indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 콘텐츠 기반 추천\n",
        "def get_content_based_recommendations(article_id, num_recommendations=5):\n",
        "    idx = indices[article_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices]\n",
        "\n",
        "# 사용자-기사 상호작용 매트릭스 생성\n",
        "interaction_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# 상호작용 매트릭스를 실수형으로 변환\n",
        "interaction_matrix = interaction_matrix.astype(np.float64)\n",
        "\n",
        "# SVD 수행\n",
        "U, sigma, Vt = svds(interaction_matrix, k=50)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# 예측 평점 계산\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "predicted_ratings = pd.DataFrame(predicted_ratings, columns=interaction_matrix.columns)\n",
        "\n",
        "# 협업 필터링 기반 추천\n",
        "def collaborative_filtering(user_id, num_recommendations=5):\n",
        "    user_idx = interaction_matrix.index.get_loc(user_id)\n",
        "    sorted_user_predictions = predicted_ratings.iloc[user_idx].sort_values(ascending=False)\n",
        "    return sorted_user_predictions.index[:num_recommendations]\n",
        "\n",
        "# 하이브리드 추천 시스템\n",
        "def hybrid_recommendation_system(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3):\n",
        "    cf_recommendations = collaborative_filtering(user_id, num_recommendations * 2)\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    cb_recommendations = []\n",
        "    for article_id in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_based_recommendations(article_id, num_recommendations=2))\n",
        "    combined_recommendations = list(set(cf_recommendations).union(set(cb_recommendations)))\n",
        "    combined_scores = {article: weight_cf for article in cf_recommendations}\n",
        "    for article in cb_recommendations:\n",
        "        if article in combined_scores:\n",
        "            combined_scores[article] += weight_cb\n",
        "        else:\n",
        "            combined_scores[article] = weight_cb\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "# 추천 결과 생성\n",
        "results = []\n",
        "for user_id in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation_system(user_id)\n",
        "    for article_id in recommendations:\n",
        "        results.append([user_id, article_id])\n",
        "\n",
        "# 결과 저장\n",
        "results_df = pd.DataFrame(results, columns=['userID', 'articleID'])\n",
        "results_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(results_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c400d5",
      "metadata": {
        "id": "d5c400d5",
        "outputId": "418d1d41-8319-4908-f2a8-a69ca88451fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1305\n",
            "1  USER_0000  ARTICLE_0084\n",
            "2  USER_0000  ARTICLE_2081\n",
            "3  USER_0000  ARTICLE_0830\n",
            "4  USER_0000  ARTICLE_2147\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from scipy.sparse.linalg import svds\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_df=0.8, min_df=2, ngram_range=(1, 2))\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['Content'])\n",
        "\n",
        "# 기사 ID를 인덱스와 매핑\n",
        "indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 콘텐츠 기반 추천\n",
        "def get_content_based_recommendations(article_id, num_recommendations=5):\n",
        "    idx = indices[article_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices]\n",
        "\n",
        "# 사용자-기사 상호작용 매트릭스 생성\n",
        "interaction_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# 상호작용 매트릭스를 실수형으로 변환\n",
        "interaction_matrix = interaction_matrix.astype(np.float64)\n",
        "\n",
        "# SVD 수행 (차원 수 조정)\n",
        "U, sigma, Vt = svds(interaction_matrix, k=100)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# 예측 평점 계산\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "predicted_ratings = pd.DataFrame(predicted_ratings, columns=interaction_matrix.columns)\n",
        "\n",
        "# 협업 필터링 기반 추천\n",
        "def collaborative_filtering(user_id, num_recommendations=5):\n",
        "    user_idx = interaction_matrix.index.get_loc(user_id)\n",
        "    sorted_user_predictions = predicted_ratings.iloc[user_idx].sort_values(ascending=False)\n",
        "    return sorted_user_predictions.index[:num_recommendations]\n",
        "\n",
        "# 하이브리드 추천 시스템\n",
        "def hybrid_recommendation_system(user_id, num_recommendations=5, weight_cf=0.7, weight_cb=0.3):\n",
        "    cf_recommendations = collaborative_filtering(user_id, num_recommendations * 2)\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    cb_recommendations = []\n",
        "    for article_id in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_based_recommendations(article_id, num_recommendations=2))\n",
        "    combined_recommendations = list(set(cf_recommendations).union(set(cb_recommendations)))\n",
        "    combined_scores = {article: weight_cf for article in cf_recommendations}\n",
        "    for article in cb_recommendations:\n",
        "        if article in combined_scores:\n",
        "            combined_scores[article] += weight_cb\n",
        "        else:\n",
        "            combined_scores[article] = weight_cb\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "# 추천 결과 생성\n",
        "results = []\n",
        "for user_id in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation_system(user_id)\n",
        "    for article_id in recommendations:\n",
        "        results.append([user_id, article_id])\n",
        "\n",
        "# 결과 저장\n",
        "results_df = pd.DataFrame(results, columns=['userID', 'articleID'])\n",
        "results_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(results_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e44ee4cd",
      "metadata": {
        "id": "e44ee4cd",
        "outputId": "b3447357-8fdd-407b-f7d5-3fe3e6f995fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3008 entries, 0 to 3007\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   articleID    3008 non-null   object\n",
            " 1   Title        3008 non-null   object\n",
            " 2   Content      3008 non-null   object\n",
            " 3   Format       3008 non-null   object\n",
            " 4   Language     3008 non-null   object\n",
            " 5   userID       3008 non-null   object\n",
            " 6   userCountry  659 non-null    object\n",
            " 7   userRegion   657 non-null    object\n",
            "dtypes: object(8)\n",
            "memory usage: 188.1+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42717 entries, 0 to 42716\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   userID       42717 non-null  object\n",
            " 1   articleID    42717 non-null  object\n",
            " 2   userRegion   42717 non-null  object\n",
            " 3   userCountry  42717 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 1.3+ MB\n",
            "None\n",
            "count      3008.000000\n",
            "mean       5428.732380\n",
            "std        6219.370202\n",
            "min         301.000000\n",
            "25%        1910.500000\n",
            "50%        3713.000000\n",
            "75%        6738.250000\n",
            "max      122568.000000\n",
            "Name: content_length, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# 데이터 분석\n",
        "print(article_info.info())\n",
        "print(view_log.info())\n",
        "\n",
        "# 기사 내용 길이 확인\n",
        "article_info['content_length'] = article_info['Content'].apply(len)\n",
        "print(article_info['content_length'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c51fdea",
      "metadata": {
        "id": "1c51fdea",
        "outputId": "f282863c-217d-49f9-bcb6-ea1d39d10627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      userID     articleID\n",
            "0  USER_0000  ARTICLE_1305\n",
            "1  USER_0000  ARTICLE_2147\n",
            "2  USER_0000  ARTICLE_1948\n",
            "3  USER_0000  ARTICLE_1281\n",
            "4  USER_0000  ARTICLE_2720\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from scipy.sparse.linalg import svds\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 로드\n",
        "article_info = pd.read_csv('./article_info.csv')\n",
        "view_log = pd.read_csv('./view_log.csv')\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_df=0.7, min_df=3, ngram_range=(1, 3))\n",
        "tfidf_matrix = tfidf.fit_transform(article_info['Content'])\n",
        "\n",
        "# 기사 ID를 인덱스와 매핑\n",
        "indices = pd.Series(article_info.index, index=article_info['articleID']).drop_duplicates()\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 콘텐츠 기반 추천\n",
        "def get_content_based_recommendations(article_id, num_recommendations=5):\n",
        "    idx = indices[article_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "    return article_info['articleID'].iloc[article_indices]\n",
        "\n",
        "# 사용자-기사 상호작용 매트릭스 생성\n",
        "interaction_matrix = view_log.pivot_table(index='userID', columns='articleID', aggfunc='size', fill_value=0)\n",
        "\n",
        "# 상호작용 매트릭스를 실수형으로 변환\n",
        "interaction_matrix = interaction_matrix.astype(np.float64)\n",
        "\n",
        "# SVD 수행 (차원 수 조정)\n",
        "U, sigma, Vt = svds(interaction_matrix, k=75)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# 예측 평점 계산\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "predicted_ratings = pd.DataFrame(predicted_ratings, columns=interaction_matrix.columns)\n",
        "\n",
        "# 협업 필터링 기반 추천\n",
        "def collaborative_filtering(user_id, num_recommendations=5):\n",
        "    user_idx = interaction_matrix.index.get_loc(user_id)\n",
        "    sorted_user_predictions = predicted_ratings.iloc[user_idx].sort_values(ascending=False)\n",
        "    return sorted_user_predictions.index[:num_recommendations]\n",
        "\n",
        "# 하이브리드 추천 시스템\n",
        "def hybrid_recommendation_system(user_id, num_recommendations=5, weight_cf=0.8, weight_cb=0.2):\n",
        "    cf_recommendations = collaborative_filtering(user_id, num_recommendations * 2)\n",
        "    viewed_articles = view_log[view_log['userID'] == user_id]['articleID'].tolist()\n",
        "    cb_recommendations = []\n",
        "    for article_id in viewed_articles:\n",
        "        cb_recommendations.extend(get_content_based_recommendations(article_id, num_recommendations=2))\n",
        "    combined_recommendations = list(set(cf_recommendations).union(set(cb_recommendations)))\n",
        "    combined_scores = {article: weight_cf for article in cf_recommendations}\n",
        "    for article in cb_recommendations:\n",
        "        if article in combined_scores:\n",
        "            combined_scores[article] += weight_cb\n",
        "        else:\n",
        "            combined_scores[article] = weight_cb\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [article for article, score in sorted_recommendations if article not in viewed_articles][:num_recommendations]\n",
        "\n",
        "# 추천 결과 생성\n",
        "results = []\n",
        "for user_id in view_log['userID'].unique():\n",
        "    recommendations = hybrid_recommendation_system(user_id)\n",
        "    for article_id in recommendations:\n",
        "        results.append([user_id, article_id])\n",
        "\n",
        "# 결과 저장\n",
        "results_df = pd.DataFrame(results, columns=['userID', 'articleID'])\n",
        "results_df.to_csv('./hybrid_recommendations_optimized.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(results_df.head())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}